# Experiment Testbed ðŸ›Œ

This directory contains all the necessary code to run experiments using the [`blocklearning`](../blocklearning/) library via Docker.

- [Structure](#structure)
- [Information](#information)
  - [Dataset Generation](#dataset-generation)
- [Setup](#setup)
  - [Model Generation](#model-generation)
  - [Generate Ethereum Accounts](#generate-ethereum-accounts)
  - [Update Genesis with Accounts](#update-genesis-with-accounts)
  - [Build Docker Images](#build-docker-images)
  - [Create Docker Network](#create-docker-network)
  - [Launch Blockchain Containers](#launch-blockchain-containers)
  - [Connect Peers](#connect-peers)
  - [Deploy the Contract](#deploy-the-contract)
  - [Launch ML Containers](#launch-ml-containers)
  - [Collect Statistics](#collect-statistics)
  - [Run Rounds](#run-rounds)
  - [Collect Logs](#collect-logs)
- [Contract](#contract)
- [IPFS](#ipfs)
- [How to Run Different Experiments](#how-to-run-different-experiments)
  - [Consensus Algorithms](#consensus-algorithms)
  - [Selection Mechanisms](#selection-mechanisms)
  - [Without Scoring Mechanisms](#without-scoring-mechanisms)
  - [With Scoring Mechanisms](#with-scoring-mechanisms)

## Structure

- `datasets/` with the datasets used for the experiments.
- `experiment/` has the models `.h5` files and the experiment results.
- `generate_cnn.py` is used to generate the CNNs used for the experiment.

## Information

This is the necessary information to reproduce exactly the experiments done during the thesis, including the same data partition and exact data model. The experiment uses IPFS to store data so it is guaranteed that all the files correspond to the original. In addition, there is a link to a [verifiable CAR file](https://car.ipfs.io/).

|File|CID|Description|
|---|---|---|
|`experiment/models/cifar10.h5`|`QmeJm6CwbDukoW881b5ELKpmuqJU7zApYyvQEZcKNRqh4v`|Cifar10 CNN|
|`experiment/models/mnist.h5`|`QmYjSQ9xCkRu8NH8aXi9RLgWE1wekVwthWrk6hoeWFBH2X`|MNIST CNN|
|`datasets/`|`QmWi9dBe56Dr8vap6qAb48hJwhkyd255UzKv4wZ9BKKj6e`|The partitioned datasets|

### Dataset Generation

Datasets are generated using [PFL-Non-IID](https://github.com/TsingZ0/PFL-Non-IID). Changes were applied to [generate_mnist.py](https://github.com/TsingZ0/PFL-Non-IID/blob/34debcc28cb278ff4a84ccc1748c7b0b7d2311c6/dataset/generate_mnist.py) such that the data is in the right order for our model. Please check [the diff](./generate_mnist.diff).

## Setup

### Model Generation

There are two available models, one for the MNIST dataset, one for the CIFAR10 dataset. They're `.h5` files can be generated by running:

```bash
python3 generate_cnn.py mnist output.h5
```

### Generate Ethereum Accounts

Generate the accounts that will be used on the network. To generate 5 accounts for miners (or validators) and 10 for trainers, run:

```bash
python3 toolkit.py generate-accounts 10 25
```

The files in `ethereum/datadir` are as follows:

- `keystore` includes the accounts information that were generated and this is necessary to start the node.
- `geth/nodekey_owner` is the node key that will be given to the "owner" RPC endpoint for our Ethereum network.
- `geth/nodekey_{i}` is the node key that will be given to the i-th Ethereum miner.
- `geth/static-nodes.json` includes the addresses that will be added as static peers to our nodes.
- `accounts.json` is the account information and password.
- `miners.json` has the public addresses generated from the private key of the miners `nodekey`. This is important for some consensus protocol genesis.

### Update Genesis with Accounts

After generating the accounts, the genesis files needs to be generated with the new accounts accounts in order to boot the network with 100 ETH in each of the accounts. To do so, run:

```bash
python3 toolkit.py update-genesis
```

### Build Docker Images

Several Docker images are used to run the Ethereum blockchain. To build then, run:

```bash
python3 toolkit.py build-images
```

### Create Docker Network

```bash
docker network create \
  --driver=bridge \
  --subnet=172.16.254.0/20 \
  bflnet
```

### Launch Blockchain Containers

For Docker compose, use:

```bash
CONSENSUS=poa MINERS=10 docker compose -f blockchain.yml -p bfl up
```

Where `CONSENSUS` = `poa|qbft|pow`.

### Connect Peers

Unfortunately, peer discovery [doesn't work with private networks](https://ethereum.stackexchange.com/questions/121380/private-network-nodes-cant-find-peers). Not even if we use a bootstrap node. Thus, we need to connect the peers to each other manually.

```bash
python3 toolkit.py connect-peers <network>
```

Where `<network>` is the ID of the Docker network where the containers are running. You can check that by running `docker network ls` and looking for `priv-eth-net`. If no network is passed, the script will try to infer the correct network.

### Deploy the Contract

The contract deployment script fetches the account to use from `ethereum/datadir/accounts.json` and uses the first account (index 0).

```bash
python3 toolkit.py deploy-contract
```

### Launch ML Containers

```bash
CONTRACT=0x8C3CBC8C31e5171C19d8a26af55E0db284Ae9b4B \
  DATASET=mnist MINERS=10 AGGREGATORS=10 SCORERS=0 TRAINERS=25 \
  SCORING="none" ABI=NoScoring \
  docker compose -f ml.yml -p bfl-ml up
```

### Collect Statistics

Start collecting statistics before running the rounds (on the results repository):

```bash
./monitor.sh
```

### Run Rounds

```bash
python3 start_round.py \
  --contract 0x8C3CBC8C31e5171C19d8a26af55E0db284Ae9b4B \
  --abi ../build/contracts/NoScoring.json \
  --rounds 50 \
  --aggregators rr
```

### Collect Logs

To collect the logs of the trainers and validators afterwards, run:

```bash
python3 toolkit.py collect-logs
```

## Contract

Some *required* base information for the contract can be found in [../contracts.json](../contracts.json). This file includes two fields that must be filled before deploying the contract:

- `model`: the IPFS CID of the exported model in `.h5` format.
- `weights` (optional): the IPFS CID with the initial weights.

## IPFS

To add any file to IPFS, run:

```
ipfs add [-r] path
```

## How to Run Different Experiments

### Consensus Algorithms

```bash
CONSENSUS=poa|pow|qbft MINERS=10 docker compose -f blockchain.yml -p bfl up

CONTRACT=0x8C3CBC8C31e5171C19d8a26af55E0db284Ae9b4B \
  DATASET=mnist MINERS=10 SERVERS=10 CLIENTS=25 \
  SCORING="none" ABI=NoScoring \
  docker compose -f ml.yml -p bfl-ml up

python3 start_round.py \
  --contract 0x8C3CBC8C31e5171C19d8a26af55E0db284Ae9b4B \
  --abi ../build/contracts/NoScoring.json \
  --rounds 50
```

### Selection Mechanisms

```bash
CONSENSUS=poa MINERS=10 docker compose -f blockchain.yml -p bfl up

CONTRACT=0xA63052D2C43CD996731937AAD7986bF8f88C2511 \
  DATASET=mnist MINERS=10 SERVERS=10 CLIENTS=25 \
  SCORING="none" ABI=FirstComeFirstServed \
  docker compose -f ml.yml -p bfl-ml up

python3 start_round.py \
  --contract 0xA63052D2C43CD996731937AAD7986bF8f88C2511 \
  --trainers fcfs \
  --abi ../build/contracts/FirstComeFirstServed.json \
  --rounds 50
```

### Without Scoring Mechanisms

```bash
CONSENSUS=poa MINERS=10 docker compose -f blockchain.yml -p bfl up

CONTRACT=0x8C3CBC8C31e5171C19d8a26af55E0db284Ae9b4B \
  DATASET=mnist MINERS=10 SERVERS=10 CLIENTS=5|10|25|50 \
  SCORING="none" ABI=NoScoring \
  docker compose -f ml.yml -p bfl-ml up

python3 start_round.py \
  --contract 0x8C3CBC8C31e5171C19d8a26af55E0db284Ae9b4B \
  --abi ../build/contracts/NoScoring.json \
  --rounds 50
```

### With Scoring Mechanisms

```bash
CONSENSUS=poa MINERS=10 docker compose -f blockchain.yml -p bfl up

CONTRACT=0x2988207C0b2666E554A803D25524B0822bd1B1A8 \
  DATASET=mnist MINERS=10 SERVERS=10 CLIENTS=5|10|25|50 \
  SCORING="<mechanism>" ABI=Scoring \
  docker compose -f ml.yml -p bfl-ml up

python3 start_round.py \
  --contract 0x2988207C0b2666E554A803D25524B0822bd1B1A8 \
  --abi ../build/contracts/Scoring.json \
  --scoring "<mechanism>" \
  --rounds 50
```
